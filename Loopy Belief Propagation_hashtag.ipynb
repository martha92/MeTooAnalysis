{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "from os.path import abspath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes = 1055\n"
     ]
    }
   ],
   "source": [
    "labels = ['pos', 'neg', 'neutral']\n",
    "pickle_in = open(\"hashtag.pickle\",\"rb\")\n",
    "[nodes, PI, SI] = pickle.load(pickle_in)\n",
    "num_nodes = len(nodes)\n",
    "print(\"Number of nodes = {}\".format(num_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:    \n",
    "    \"\"\" Timer \"\"\"\n",
    "    def __enter__(self):\n",
    "        self.start = time.clock() # start\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.end = time.clock() # end\n",
    "        self.i = self.end - self.start # time taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psi(SI):\n",
    "    PSI = np.zeros((num_nodes, num_nodes))\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            try:\n",
    "                PSI[i][j] = SI[nodes[i], nodes[j]]\n",
    "                PSI[j][i] = SI[nodes[i], nodes[j]]\n",
    "            except:\n",
    "                try:\n",
    "                    PSI[i][j] = SI[nodes[j], nodes[i]]\n",
    "                    PSI[j][i] = SI[nodes[j], nodes[i]]\n",
    "                except:\n",
    "                    None\n",
    "    return PSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phi(PI):\n",
    "    PHI = np.zeros((num_nodes, len(labels)))\n",
    "    for node in range(num_nodes):\n",
    "        for label in range(len(labels)):\n",
    "            try:\n",
    "                PHI[node][label] = PI[labels[label], nodes[node]]\n",
    "            except:\n",
    "                PHI[node][label] = 0.0\n",
    "    return PHI   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMessage(i, PHIi, PSIi, label_j, labels, neighbours, messages):\n",
    "    m = { label: np.zeros(messages[label].shape[0]) for label in labels } # initialise\n",
    "    zeros = np.zeros(len(PSIi))\n",
    "\n",
    "    for neighbour in neighbours:\n",
    "        S = set(neighbours) - {neighbour}\n",
    "        for label in labels: # compute contribution to each neighbour from all other neighbours of i\n",
    "            m[label][neighbour] = np.prod([ messages[label][k,i] for k in S ]) + .00000001\n",
    "\n",
    "    return sum( np.multiply(PHIi[i] * (PSIi if label_i == label_j else zeros), m[label_i]) for i, label_i in enumerate(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(i, PHIi, labels, neighbours, messages):\n",
    "    scores = { label: PHIi[label_i] * np.prod([ messages[label][j,i] for j in neighbours ]) for label_i, label in enumerate(labels) }\n",
    "    # normalise scores\n",
    "    alpha = sum( scores[label] for label in labels )\n",
    "    if alpha:\n",
    "        for label in labels:\n",
    "            scores[label] *= 1 / alpha\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(scores):\n",
    "    return [ max(score, key=score.get) for score in scores ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LBP(labels, nodes, PI, SI):\n",
    "    with Timer() as t: # do some extra initialisation\n",
    "        PSI = get_psi(SI) # Convert the SI value to matrix representation\n",
    "        PHI = get_phi(PI) # Convert sentiment probablity to matrix representation\n",
    "        messages = { label: (PSI > 0).astype(float) for label in labels } # Initialize the message values to 1 for co-occuring nodes \n",
    "        neighbours = [ list(np.nonzero(PSI[i])[0]) for i in range(num_nodes) ] # extract neighbours for all nodes\n",
    "        print('PSI = {}, PHI = {}'.format(PHI.shape, PSI.shape))\n",
    "    print(\"\\nStarting propagation on {} node hashtag graph\".format(num_nodes))\n",
    "\n",
    "    loops = 0 # loop variable t\n",
    "    while True:\n",
    "        with Timer() as t: # compute messages\n",
    "            loops += 1\n",
    "            old_messages = { label: messages[label].copy() for label in labels } # archive messages\n",
    "#             print('1')\n",
    "            for i in range(num_nodes): # for each node\n",
    "                for label in labels: # compute message from node i to its neighbours\n",
    "                    messages[label][i,:] = getMessage(i, PHI[i,:].flatten(), PSI[i,:].flatten(), label, labels, neighbours[i], old_messages)\n",
    "#                 print('2')\n",
    "                alpha = [ alpha for alpha in map(lambda x : 1/x if x else 1, np.sum([ messages[label][i,:] for label in labels ], axis=0)) ] # compute normaliser\n",
    "                for label in labels:\n",
    "                    messages[label][i,:] *= alpha # normalise messages\n",
    "#         print('3')\n",
    "        print(\"[{:.3f}s] Loop {} completed.\\tMessage change: {}\".format(t.i, loops, np.sum([ abs(old_messages[label] - messages[label]) for label in labels ])))\n",
    "\n",
    "        if np.product([ np.allclose(old_messages[label], messages[label]) for label in labels ]) or loops > 10: # halt if messages stop changing\n",
    "            break\n",
    "\n",
    "    print(\"Propagation complete.\\n\")\n",
    "    \n",
    "    with Timer() as t: # compute final labels\n",
    "        scores = [ getScores(i, PHI[i,:], labels, neighbours[i], messages) for i in range(num_nodes)]\n",
    "        results = getLabels(scores)\n",
    "\n",
    "    print(\"[{:.3f}s] Final labels computed. Objective value: {}\".format(t.i, sum( max(score.values()) for score in scores )))\n",
    "\n",
    "    return results, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResults(labels, nodes, results, scores):\n",
    "    filename = 'LBP_ouput.results'\n",
    "    with open(filename, 'w') as fo:\n",
    "        fo.write(\"ID\\tNode\\tLabel\\t{}\\n\".format('\\t'.join(labels)))\n",
    "        for i in range(len(nodes)):\n",
    "            fo.write(\"{}\\t{}\\t{}\\t{}\\n\".format(i, nodes[i], results[i], '\\t'.join(str(scores[i][label]) for label in labels)))\n",
    "            \n",
    "    print(\"Results written to '{}'.\".format(abspath(filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSI = (1055, 3), PHI = (1055, 1055)\n",
      "\n",
      "Starting propagation on 1055 node hashtag graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208.611s] Loop 1 completed.\tMessage change: 459308.00000000023\n",
      "[215.800s] Loop 2 completed.\tMessage change: 74.64686523136525\n",
      "[259.132s] Loop 3 completed.\tMessage change: 3.3754105792103863\n",
      "[219.430s] Loop 4 completed.\tMessage change: 0.0018554937039891636\n",
      "[220.667s] Loop 5 completed.\tMessage change: 5.317366202033022e-05\n",
      "Propagation complete.\n",
      "\n",
      "[0.438s] Final labels computed. Objective value: 1000.6665139425836\n",
      "Results written to '/home/hadoop/Documents/BD_Project/MeTooAnalysis-master/twitter/ouput.results'.\n"
     ]
    }
   ],
   "source": [
    "results, scores = LBP(labels, nodes, PI, SI) # run propagation\n",
    "printResults(labels, nodes, results, scores) # print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
